{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNT+rNH4Y+fDHF2EwdpZ9Ph",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/THEOPHILUSg48/Mini_Project_2025/blob/main/Demo_count.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q08TAYoFYDkK"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "# NOTE: Make sure to install the libraries first:\n",
        "# pip install opencv-python numpy ultralytics\n",
        "\n",
        "from ultralytics import YOLO\n",
        "# DeepSORT is often integrated by setting the 'tracker' argument in model.track()\n",
        "# (e.g., tracker='bytetrack.yaml'), so a separate import is usually not needed.\n",
        "\n",
        "# --- 1. Configuration ---\n",
        "# The path below suggests you are running this in a Linux/Colab environment.\n",
        "# Please ensure this file name EXACTLY matches the file name in your '/content/' directory.\n",
        "VIDEO_SOURCE = r'/content/4K Road traffic video for object detection and tracking - free download now!.mp4'\n",
        "# These classes must match the output labels from the YOLO model (COCO dataset)\n",
        "CLASSES_TO_COUNT = ['car', 'truck', 'bus', 'motorcycle']\n",
        "# Define the virtual counting line (Trip Wire)\n",
        "COUNTING_LINE_Y = 300\n",
        "LINE_THICKNESS = 5\n",
        "CLASS_COLORS = {\n",
        "    'car': (255, 0, 0),        # Blue in BGR\n",
        "    'truck': (0, 255, 255),    # Yellow in BGR\n",
        "    'motorcycle': (0, 255, 0), # Green in BGR\n",
        "    'bus': (255, 100, 255)     # Purple in BGR\n",
        "}\n",
        "\n",
        "# --- 2. Tracking State Management (TrafficCounter Class) ---\n",
        "\n",
        "class TrafficCounter:\n",
        "    \"\"\"Manages vehicle tracking state and counts based on the trip wire logic.\"\"\"\n",
        "    def __init__(self, counting_line_y, classes):\n",
        "        self.counting_line_y = counting_line_y\n",
        "        # Stores the state of each tracked object: {id: {'class': str, 'crossed': bool}}\n",
        "        self.vehicle_state = {}\n",
        "        # Stores the final counts: {'car': 0, 'truck': 0, ...}\n",
        "        self.counts = {cls: 0 for cls in classes}\n",
        "\n",
        "    def update(self, track_id, object_class, centroid_y):\n",
        "        \"\"\"Updates the state and increments count if the trip wire is crossed.\"\"\"\n",
        "\n",
        "        # 1. Initialize or retrieve state\n",
        "        if track_id not in self.vehicle_state:\n",
        "            self.vehicle_state[track_id] = {'class': object_class, 'crossed': False}\n",
        "\n",
        "        state = self.vehicle_state[track_id]\n",
        "\n",
        "        # 2. Crossing Detection (Moving downwards across the line)\n",
        "        if centroid_y >= self.counting_line_y and not state['crossed']:\n",
        "            # Increment the count for the specific class\n",
        "            if object_class in self.counts:\n",
        "                self.counts[object_class] += 1\n",
        "                state['crossed'] = True\n",
        "                print(f\"Counted: {object_class} (ID: {track_id}). Total {object_class}: {self.counts[object_class]}\")\n",
        "\n",
        "# --- 3. Main Processing Loop ---\n",
        "\n",
        "def run_vehicle_counter():\n",
        "    \"\"\"\n",
        "    Main function to initialize the YOLOv8 model, read video, and process frames.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"--- Initializing YOLOv8 Model and Video Stream ---\")\n",
        "\n",
        "    # 3a. Model Loading\n",
        "    try:\n",
        "        # Load the pre-trained nano version of YOLOv8 for speed\n",
        "        model = YOLO('yolov8n.pt')\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading YOLO model: {e}\")\n",
        "        print(\"Please ensure you have run 'pip install ultralytics' and have network access to download weights.\")\n",
        "        return\n",
        "\n",
        "    # --- CHECK 1: Use os.path.exists for better debugging ---\n",
        "    if not os.path.exists(VIDEO_SOURCE):\n",
        "        print(f\"\\nFATAL ERROR: The video file was not found at the specified location.\")\n",
        "        print(f\"Checked Path: '{VIDEO_SOURCE}'\")\n",
        "        print(\"-\" * 50)\n",
        "        print(\"TROUBLESHOOTING TIP (If using Colab/Cloud Notebook):\")\n",
        "        print(\"1. **Verify File Name:** Run `!ls /content/` in a separate cell to check the exact file name.\")\n",
        "        print(\"2. **Rename File:** We highly recommend renaming your video file to something simple, like `traffic.mp4`, to avoid issues with spaces and special characters.\")\n",
        "        print(\"-\" * 50)\n",
        "        return\n",
        "\n",
        "    cap = cv2.VideoCapture(VIDEO_SOURCE)\n",
        "    if not cap.isOpened():\n",
        "        # This error typically means permissions or an unsupported codec.\n",
        "        print(f\"\\nError: Could not open video file at '{VIDEO_SOURCE}'\")\n",
        "        print(\"Possible Issue: Video file exists but OpenCV cannot read it (e.g., codec not supported or permissions issue).\")\n",
        "        return\n",
        "\n",
        "    # Initialize the custom counter logic\n",
        "    traffic_counter = TrafficCounter(COUNTING_LINE_Y, CLASSES_TO_COUNT)\n",
        "\n",
        "    frame_count = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Import cv2_imshow from google.colab.patches\n",
        "    from google.colab.patches import cv2_imshow\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame_height, frame_width, _ = frame.shape\n",
        "\n",
        "        # --- 3b. Object Detection & Tracking (YOLOv8 with ByteTrack) ---\n",
        "        # The 'tracker' argument enables multi-object tracking (DeepSORT equivalent)\n",
        "        results = model.track(frame, persist=True, tracker='bytetrack.yaml', verbose=False)\n",
        "\n",
        "        # --- 3c. Parsing and Counting Logic ---\n",
        "\n",
        "        # Draw the virtual trip wire\n",
        "        cv2.line(frame, (0, COUNTING_LINE_Y), (frame_width, COUNTING_LINE_Y), (0, 0, 255), LINE_THICKNESS)\n",
        "        cv2.putText(frame, 'COUNTING LINE', (frame_width - 300, COUNTING_LINE_Y - 15),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "\n",
        "        # Process results only if tracking data is present\n",
        "        if results and results[0].boxes.id is not None:\n",
        "\n",
        "            # Extract relevant tensors from the first result object\n",
        "            boxes = results[0].boxes.xyxy.cpu().numpy()\n",
        "            track_ids = results[0].boxes.id.cpu().numpy()\n",
        "            classes = results[0].boxes.cls.cpu().numpy()\n",
        "            class_names = results[0].names\n",
        "\n",
        "            for box, track_id, cls_index in zip(boxes, track_ids, classes):\n",
        "\n",
        "                obj_class = class_names[int(cls_index)]\n",
        "\n",
        "                # Check if the detected object is one we want to count\n",
        "                if obj_class in traffic_counter.counts:\n",
        "\n",
        "                    x1, y1, x2, y2 = map(int, box)\n",
        "\n",
        "                    # Calculate centroid (Center Point Tracking)\n",
        "                    center_x = int((x1 + x2) / 2)\n",
        "                    center_y = int((y1 + y2) / 2)\n",
        "\n",
        "                    # Update Counter Logic (Core Trip Wire Check)\n",
        "                    traffic_counter.update(int(track_id), obj_class, center_y)\n",
        "\n",
        "                    # Draw Bounding Box and ID (Visualization)\n",
        "                    color = CLASS_COLORS.get(obj_class, (255, 255, 255))\n",
        "                    cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
        "                    cv2.putText(frame, f\"ID:{int(track_id)} {obj_class}\", (x1, y1 - 10),\n",
        "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "                    cv2.circle(frame, (center_x, center_y), 4, (0, 0, 255), -1)\n",
        "\n",
        "\n",
        "        # Display the counts on the frame\n",
        "        y_offset = 30\n",
        "        for cls, count in traffic_counter.counts.items():\n",
        "            text = f\"{cls.capitalize()} Count: {count}\"\n",
        "            cv2.putText(frame, text, (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "            y_offset += 30\n",
        "\n",
        "        # Show the processed frame\n",
        "        cv2_imshow(frame)\n",
        "\n",
        "        # Exit if 'q' is pressed\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "        frame_count += 1\n",
        "\n",
        "    # --- 3e. Data Logging (Blueprint Phase 5) ---\n",
        "    end_time = time.time()\n",
        "    duration = end_time - start_time\n",
        "    fps = frame_count / duration if duration > 0 else 0\n",
        "\n",
        "    print(f\"\\n--- Analysis Complete ---\")\n",
        "    print(f\"Total Frames Processed: {frame_count}\")\n",
        "    print(f\"Total Duration (s): {duration:.2f}\")\n",
        "    print(f\"Average FPS: {fps:.2f}\")\n",
        "    print(\"Final Counts:\", traffic_counter.counts)\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    run_vehicle_counter()"
      ]
    }
  ]
}